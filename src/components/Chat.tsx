import React, { useState, useRef, useEffect, RefObject, useMemo } from 'react';
import { useNavigate } from 'react-router-dom';
import { FileCode, Plus, Image as ImageIcon, X, ChevronRight, MousePointer2 } from 'lucide-react';
import { useStore } from '../store';
import { sendMessage, Message, ToolCall } from '../lib/ai';
import { mountFiles } from '../lib/webcontainer';
import { executeTool, ToolContext } from '../lib/tools';
import { BASE_PROJECT_FILES } from '../lib/projectTemplate';
import { saveChatMessages, saveProject, createChat } from '../lib/api';
import { generateAndSaveTitle } from '../lib/titleGenerator';
import { ActionsList, StreamingAction } from './ActionsList';
import { MermaidBlock } from './MermaidBlock';
import { ImageViewer } from './ImageViewer';
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';
import { getSystemPrompt } from '../lib/systemPrompts';

// Keep for future use
// const MODELS: ModelType[] = ['glm-4.7'];
// const MODEL_NAMES = { 'glm-4.7': 'GLM 4.7' };

// Attachment interface
interface FileAttachment {
    name: string;
    type: string;
    size: number;
    content?: string; // Store content for transfer to workbench
}

// Helper to group messages for UI
type ContentType = string | null | Array<{ type: 'text'; text: string } | { type: 'image_url'; image_url: { url: string } }>;

interface AssistantSegment {
    type: 'text' | 'tools';
    content?: ContentType;
    toolCalls?: { call: ToolCall; result?: string }[];
}

interface MessageGroup {
    role: 'user' | 'assistant';
    content: ContentType; // For user messages and backward compat
    thinking?: string;
    thinkingDuration?: number;
    attachments?: FileAttachment[];
    toolCalls?: {
        call: ToolCall;
        result?: string;
    }[];
    // Ordered segments for assistant messages (text and tool blocks in sequence)
    segments?: AssistantSegment[];
}

interface ChatProps {
    scrollRef?: RefObject<HTMLDivElement>;
    onScroll?: (e: React.UIEvent<HTMLDivElement>) => void;
}

const getActionDisplayName = (toolName: string, args: string): string => {
    if (!toolName) return 'Preparing...';

    const decodeHtml = (text: string): string => {
        return text
            .replace(/&amp;/g, '&')
            .replace(/&lt;/g, '<')
            .replace(/&gt;/g, '>')
            .replace(/&quot;/g, '"')
            .replace(/&#39;/g, "'");
    };

    const extract = (key: string) => {
        const match = args.match(new RegExp(`"${key}"\\s*:\\s*"([^"]*)`));
        return match ? decodeHtml(match[1]) : '';
    };

    try {
        const parsed = JSON.parse(args);
        switch (toolName) {
            case 'createFile': return parsed.path || '';
            case 'editFile': return parsed.path || '';
            case 'readFile': return parsed.path || '';
            case 'readMultipleFiles': return `${(parsed.paths || []).length} files`;
            case 'deleteFile': return parsed.path || '';
            case 'renameFile': return parsed.oldPath ? `${parsed.oldPath} â†’ ${parsed.newPath}` : '';
            case 'runCommand': return decodeHtml(parsed.command || '');
            case 'searchWeb': return decodeHtml(parsed.query || '');
            case 'searchInFiles': return decodeHtml(parsed.query || '');
            case 'extractPage': return parsed.url || '';
            case 'typeCheck': return 'Workspace';
            case 'lintCheck': return parsed.path || 'src/';
            case 'listFiles': return 'Workspace';
            case 'getErrors': return 'Workspace';
            case 'batchCreateFiles': return `${(parsed.files || []).length} files`;
            case 'checkDependencies': return 'package.json';
            default: return '';
        }
    } catch {
        switch (toolName) {
            case 'createFile':
            case 'editFile':
            case 'readFile':
            case 'deleteFile':
            case 'lintCheck':
                return extract('path');
            case 'readMultipleFiles':
                return 'Multiple files';
            case 'renameFile':
                const oldP = extract('oldPath');
                const newP = extract('newPath');
                return oldP ? `${oldP} â†’ ${newP}` : oldP;
            case 'runCommand': return extract('command');
            case 'searchWeb':
            case 'searchInFiles':
                return extract('query');
            case 'extractPage': return extract('url');
            case 'batchCreateFiles': return 'Multiple files';
            case 'getErrors': return 'Workspace';
            case 'checkDependencies': return 'package.json';
            default: return '';
        }
    }
};

export function Chat({ scrollRef, onScroll }: ChatProps) {
    const navigate = useNavigate();
    const messages = useStore(s => s.messages);
    const addMessage = useStore(s => s.addMessage);
    const setMessages = useStore(s => s.setMessages);
    const selectedModel = useStore(s => s.selectedModel);
    const addTerminalOutput = useStore(s => s.addTerminalOutput);
    const updateLastMessage = useStore(s => s.updateLastMessage);
    const user = useStore(s => s.user);
    const currentChatId = useStore(s => s.currentChatId);
    const setCurrentChatId = useStore(s => s.setCurrentChatId);
    const theme = useStore(s => s.theme);
    const setSelectedFile = useStore(s => s.setSelectedFile);
    const setTokenCount = useStore(s => s.setTokenCount);
    const tokenCount = useStore(s => s.tokenCount);
    const modelContextLimit = useStore(s => s.modelContextLimit);
    const setSystemPrompt = useStore(s => s.setSystemPrompt);
    const selectedElement = useStore(s => s.selectedElement);
    const setSelectedElement = useStore(s => s.setSelectedElement);

    // Local actions state
    const [actions, setActions] = useState<StreamingAction[]>([]);

    // Action helpers
    const addAction = (toolName: string, displayName: string) => {
        const id = Math.random().toString(36).substring(7);
        setActions(prev => [...prev, {
            id,
            toolName,
            displayName,
            status: 'pending'
        }]);
        return id;
    };



    const updateAction = (id: string, updates: Partial<StreamingAction>) => {
        setActions(prev => prev.map(a =>
            a.id === id ? { ...a, ...updates } : a
        ));
    };

    const isDark = theme === 'dark';
    const [input, setInput] = useState('');
    const [isLoading, setIsLoading] = useState(false);
    const [currentThinking, setCurrentThinking] = useState<string>('');
    const [thinkingDuration, setThinkingDuration] = useState<number>(0);
    const [thinkingStartTime, setThinkingStartTime] = useState<number | null>(null);
    const messagesEndRef = useRef<HTMLDivElement>(null);
    const abortControllerRef = useRef<AbortController | null>(null);

    // Set system prompt in store for reference
    useEffect(() => {
        if (user) {
            const prompt = getSystemPrompt(selectedModel);
            setSystemPrompt(prompt);
        }
    }, [user, selectedModel]);

    const scrollToBottom = () => {
        messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
    };

    useEffect(() => {
        scrollToBottom();
    }, [messages]);

    // Initialize base project when chat starts
    const projectInitializedRef = useRef<string | null>(null);

    const initializeBaseProject = async () => {
        if (!currentChatId || projectInitializedRef.current === currentChatId) return;

        const state = useStore.getState();
        // Only initialize if no files exist yet
        if (Object.keys(state.files).length === 0) {
            projectInitializedRef.current = currentChatId;

            try {
                // Mount base project files to WebContainer
                await mountFiles(BASE_PROJECT_FILES);

                // Update store with base files
                state.setFiles(BASE_PROJECT_FILES);

                console.log('Base React project initialized');
            } catch (err) {
                console.error('Failed to initialize base project:', err);
            }
        }
    };

    // Load saved messages when opening an existing chat
    useEffect(() => {
        const loadChatMessages = async () => {
            if (currentChatId && user) {
                try {
                    const { getChatMessages } = await import('../lib/api');
                    const data = await getChatMessages(currentChatId);
                    if (data.messages && data.messages.length > 0) {
                        // Only load if we don't have messages already (to avoid overwriting during active chat)
                        if (messages.length === 0) {
                            setMessages(data.messages);
                        }
                    }
                } catch (err) {
                    console.error('Failed to load chat messages:', err);
                }
            }
        };
        loadChatMessages();
    }, [currentChatId, user]);

    // Auto-process first message from HomePage
    const autoProcessedRef = useRef<string | null>(null);
    useEffect(() => {
        // If we have exactly 1 user message and haven't processed it for this chat, trigger submit
        if (
            messages.length === 1 &&
            messages[0].role === 'user' &&
            !isLoading &&
            currentChatId &&
            autoProcessedRef.current !== currentChatId
        ) {
            autoProcessedRef.current = currentChatId;

            // Initialize base project first
            initializeBaseProject().then(() => {
                // Check for documents from HomePage
                const storedDocs = sessionStorage.getItem(`chat_docs_${currentChatId}`);
                let aiMessage = messages[0];

                if (storedDocs) {
                    try {
                        const docs = JSON.parse(storedDocs) as { name: string; content: string; type: string }[];
                        sessionStorage.removeItem(`chat_docs_${currentChatId}`);

                        // Build AI message with full file contents
                        const displayContent = typeof messages[0].content === 'string'
                            ? messages[0].content
                            : (messages[0].content as any[]).find(p => p.type === 'text')?.text || '';

                        // Remove file names from display text to get original input
                        const originalInput = displayContent.split('\nðŸ“Ž')[0].trim();

                        const docsContext = docs.map(doc =>
                            `\n\n[User attached file: ${doc.name}]\n\`\`\`${doc.type.split('/')[1] || 'text'}\n${doc.content}\n\`\`\``
                        ).join('');
                        const aiText = originalInput + docsContext;

                        aiMessage = { role: 'user', content: aiText };
                    } catch (e) {
                        console.error('Error parsing stored docs:', e);
                    }
                }

                // Trigger the AI response with the message (with full docs if any)
                triggerAIResponse(aiMessage, currentChatId);
            });
        }
    }, [messages, currentChatId, isLoading]);

    // Auto-setup template project
    const templateSetupRef = useRef<string | null>(null);
    useEffect(() => {
        if (!currentChatId || isLoading || templateSetupRef.current === currentChatId) return;

        const templateFlag = sessionStorage.getItem(`template_setup_${currentChatId}`);
        if (templateFlag) {
            templateSetupRef.current = currentChatId;
            sessionStorage.removeItem(`template_setup_${currentChatId}`);

            // Add user message for setup
            const setupMessage: Message = {
                role: 'user',
                content: 'Install dependencies and run the project. Show me the preview.'
            };
            addMessage(setupMessage);

            // Trigger AI response
            setTimeout(() => {
                triggerAIResponse(setupMessage, currentChatId);
            }, 100);
        }
    }, [currentChatId, isLoading]);

    // Auto-trigger AI in forked chats â€” detect fork_context flag from sessionStorage
    const forkSetupRef = useRef<string | null>(null);
    useEffect(() => {
        if (!currentChatId || isLoading || forkSetupRef.current === currentChatId) return;

        const forkFlag = sessionStorage.getItem(`fork_context_${currentChatId}`);
        if (forkFlag) {
            forkSetupRef.current = currentChatId;
            // Prevent auto-process hook from also triggering on this chat
            autoProcessedRef.current = currentChatId;
            sessionStorage.removeItem(`fork_context_${currentChatId}`);

            // Initialize base project, then send context recovery message
            initializeBaseProject().then(() => {
                const forkMessage: Message = {
                    role: 'user',
                    content: 'Continue working on the project. Read .glovix/context.md for context from the previous chat.'
                };
                addMessage(forkMessage);

                setTimeout(() => {
                    triggerAIResponse(forkMessage, currentChatId);
                }, 100);
            });
        }
    }, [currentChatId, isLoading]);

    // Group messages: user messages are standalone, consecutive assistant+tool messages form one group with segments
    const groupedMessages = useMemo(() => {
        const groups: MessageGroup[] = [];
        let currentGroup: MessageGroup | null = null;

        for (const msg of messages) {
            if (msg.role === 'user') {
                if (currentGroup) groups.push(currentGroup);
                currentGroup = {
                    role: 'user',
                    content: msg.content,
                    attachments: (msg as any).attachments,
                    pickedElement: (msg as any).pickedElement
                } as any;
            } else if (msg.role === 'assistant') {
                if (currentGroup && currentGroup.role === 'assistant') {
                    if (!currentGroup.segments) currentGroup.segments = [];

                    if (msg.content) {
                        const textContent = typeof msg.content === 'string' ? msg.content : '';
                        if (textContent) {
                            const lastSeg = currentGroup.segments[currentGroup.segments.length - 1];
                            if (lastSeg && lastSeg.type === 'text' && typeof lastSeg.content === 'string') {
                                lastSeg.content += '\n\n' + textContent;
                            } else {
                                currentGroup.segments.push({ type: 'text', content: textContent });
                            }
                        }
                    }

                    if (msg.tool_calls && msg.tool_calls.length > 0) {
                        const newCalls = msg.tool_calls.map(tc => ({ call: tc }));
                        const lastSeg = currentGroup.segments[currentGroup.segments.length - 1];
                        if (lastSeg && lastSeg.type === 'tools') {
                            lastSeg.toolCalls!.push(...newCalls);
                        } else {
                            currentGroup.segments.push({ type: 'tools', toolCalls: newCalls });
                        }
                        if (!currentGroup.toolCalls) currentGroup.toolCalls = [];
                        currentGroup.toolCalls.push(...newCalls);
                    }

                    if (!currentGroup.thinking && (msg as any).thinking) {
                        currentGroup.thinking = (msg as any).thinking;
                    }
                    if (!currentGroup.thinkingDuration && (msg as any).thinkingDuration) {
                        currentGroup.thinkingDuration = (msg as any).thinkingDuration;
                    }
                } else {
                    if (currentGroup) groups.push(currentGroup);

                    const segments: AssistantSegment[] = [];
                    if (msg.content) {
                        segments.push({ type: 'text', content: msg.content });
                    }
                    if (msg.tool_calls && msg.tool_calls.length > 0) {
                        segments.push({ type: 'tools', toolCalls: msg.tool_calls.map(tc => ({ call: tc })) });
                    }

                    currentGroup = {
                        role: 'assistant',
                        content: msg.content,
                        thinking: (msg as any).thinking,
                        thinkingDuration: (msg as any).thinkingDuration,
                        toolCalls: msg.tool_calls?.map(tc => ({ call: tc })),
                        segments
                    };
                }
            } else if (msg.role === 'tool') {
                if (currentGroup) {
                    const output = typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content) || '';

                    if (currentGroup.toolCalls) {
                        const toolCallIndex = currentGroup.toolCalls.findIndex(tc => tc.call.id === msg.tool_call_id);
                        if (toolCallIndex !== -1) {
                            currentGroup.toolCalls[toolCallIndex].result = output;
                        }
                    }

                    if (currentGroup.segments) {
                        for (const seg of currentGroup.segments) {
                            if (seg.type === 'tools' && seg.toolCalls) {
                                const tc = seg.toolCalls.find(tc => tc.call.id === msg.tool_call_id);
                                if (tc) {
                                    tc.result = output;
                                    break;
                                }
                            }
                        }
                    }

                    if (output.includes('```mermaid')) {
                        if (currentGroup.segments) {
                            const lastTextSeg = [...currentGroup.segments].reverse().find(s => s.type === 'text');
                            if (lastTextSeg && typeof lastTextSeg.content === 'string') {
                                lastTextSeg.content += '\n\n' + output;
                            } else {
                                currentGroup.segments.push({ type: 'text', content: output });
                            }
                        }
                    }
                }
            }
        }
        if (currentGroup) groups.push(currentGroup);
        return groups;
    }, [messages]);

    const handleStop = () => {
        if (abortControllerRef.current) {
            abortControllerRef.current.abort();
            abortControllerRef.current = null;
            setIsLoading(false);
            setActions([]);
            setCurrentThinking('');
        }
    };

    // Tool execution context
    const toolContext: ToolContext = {
        addTerminalOutput,
        setSelectedFile
    };

    const handleToolCall = async (toolCall: ToolCall): Promise<string> => {
        const { name, arguments: argsString } = toolCall.function;
        const result = await executeTool(name, argsString, toolContext);

        // Auto-retry logic for editFile failures: read the file and provide content in error
        if (name === 'editFile' && result.includes('Error editing') && result.includes('Could not find')) {
            try {
                const args = JSON.parse(argsString);
                if (args.path) {
                    const fileContent = await executeTool('readFile', JSON.stringify({ path: args.path }), toolContext);
                    return `${result}\n\nðŸ“„ Current file content for reference:\n${fileContent}`;
                }
            } catch {
                // If we can't parse args, just return original error
            }
        }

        return result;
    };

    const [selectedImages, setSelectedImages] = useState<string[]>([]);
    const [selectedDocuments, setSelectedDocuments] = useState<{ name: string; content: string; type: string }[]>([]);
    const fileInputRef = useRef<HTMLInputElement>(null);
    const documentInputRef = useRef<HTMLInputElement>(null);

    const handleImageSelect = (e: React.ChangeEvent<HTMLInputElement>) => {
        if (e.target.files) {
            const files = Array.from(e.target.files);
            files.forEach(file => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    setSelectedImages(prev => [...prev, reader.result as string]);
                };
                reader.readAsDataURL(file);
            });
        }
    };

    const handleDocumentSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {
        if (e.target.files) {
            const files = Array.from(e.target.files);
            for (const file of files) {
                try {
                    const content = await readDocumentContent(file);
                    setSelectedDocuments(prev => [...prev, {
                        name: file.name,
                        content,
                        type: file.type || getFileType(file.name)
                    }]);
                } catch (err) {
                    console.error('Error reading file:', err);
                }
            }
        }
    };

    const getFileType = (filename: string): string => {
        const ext = filename.split('.').pop()?.toLowerCase() || '';
        const typeMap: Record<string, string> = {
            'txt': 'text/plain',
            'md': 'text/markdown',
            'json': 'application/json',
            'js': 'text/javascript',
            'ts': 'text/typescript',
            'tsx': 'text/typescript',
            'jsx': 'text/javascript',
            'css': 'text/css',
            'html': 'text/html',
            'py': 'text/python',
            'java': 'text/java',
            'c': 'text/c',
            'cpp': 'text/cpp',
            'rs': 'text/rust',
            'go': 'text/go',
            'sql': 'text/sql',
            'yaml': 'text/yaml',
            'yml': 'text/yaml',
            'xml': 'text/xml',
            'csv': 'text/csv',
        };
        return typeMap[ext] || 'text/plain';
    };

    const readDocumentContent = (file: File): Promise<string> => {
        return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = () => {
                const content = reader.result as string;
                resolve(content);
            };
            reader.onerror = () => reject(reader.error);
            reader.readAsText(file);
        });
    };

    const handlePaste = (e: React.ClipboardEvent) => {
        const items = e.clipboardData.items;
        for (let i = 0; i < items.length; i++) {
            if (items[i].type.indexOf('image') !== -1) {
                const blob = items[i].getAsFile();
                if (blob) {
                    const reader = new FileReader();
                    reader.onloadend = () => {
                        setSelectedImages(prev => [...prev, reader.result as string]);
                    };
                    reader.readAsDataURL(blob);
                }
            }
        }
    };

    const handleDrop = (e: React.DragEvent) => {
        e.preventDefault();
        const files = Array.from(e.dataTransfer.files);
        files.forEach(file => {
            if (file.type.startsWith('image/')) {
                const reader = new FileReader();
                reader.onloadend = () => {
                    setSelectedImages(prev => [...prev, reader.result as string]);
                };
                reader.readAsDataURL(file);
            }
        });
    };

    const textareaRef = useRef<HTMLTextAreaElement>(null);

    // Core AI processing function
    const triggerAIResponse = async (userMessage: Message, chatIdOverride?: string) => {
        if (isLoading) return;

        setIsLoading(true);
        abortControllerRef.current = new AbortController();

        const chatId = chatIdOverride || currentChatId;

        const apiKey = import.meta.env.VITE_CANOPYWAVE_API_KEY;

        // Get current project files for context
        const currentFiles = useStore.getState().files;
        const fileList = Object.keys(currentFiles).filter(f => f !== 'glovix-picker.js').sort().join('\n') ||
            'package.json, vite.config.ts, tsconfig.json, tailwind.config.js, postcss.config.js, index.html, src/main.tsx, src/App.tsx, src/index.css';

        // Build system prompt â€” always get fresh from getSystemPrompt
        const currentSystemPrompt = getSystemPrompt(selectedModel);
        const promptContent = currentSystemPrompt
            ? currentSystemPrompt.replace('{{FILE_LIST}}', fileList)
            : `You are Glovix, an AI web developer. Project files: ${fileList}. Use tools to create/modify files. Run pnpm install then pnpm run dev to start.`;

        const SYSTEM_PROMPT: Message = {
            role: 'system',
            content: promptContent
        };

        // Use model context limit from settings (or default to 200k)
        const modelContextLimit = useStore.getState().modelContextLimit || 200000;
        const MAX_CONTEXT_TOKENS = Math.floor(modelContextLimit * 0.8); // Use 80% to leave room for response

        const estimateTokens = (text: string) => Math.ceil(text.length / 4);

        const getMessageTokens = (msg: any) => {
            let tokens = 0;
            if (typeof msg.content === 'string') {
                tokens += estimateTokens(msg.content);
            } else if (Array.isArray(msg.content)) {
                tokens += msg.content.reduce((sum: number, part: any) => {
                    if (part.type === 'text') return sum + estimateTokens(part.text);
                    return sum + 1000; // Rough estimate for images
                }, 0);
            }
            if (msg.tool_calls) {
                tokens += msg.tool_calls.reduce((sum: number, tc: any) =>
                    sum + estimateTokens(tc.function?.name || '') + estimateTokens(tc.function?.arguments || ''), 0);
            }
            return tokens;
        };

        // Get current messages from store (not from hook to ensure freshness)
        const currentStoreMessages = useStore.getState().messages;

        // Filter out truly invalid messages (but keep assistant placeholders and tool messages)
        const validMessages = currentStoreMessages.filter((msg) => {
            if (!msg.role) return false;
            // System messages need content
            if (msg.role === 'system') return !!msg.content;
            // Tool messages need tool_call_id
            if (msg.role === 'tool') return !!msg.tool_call_id;
            // Assistant messages: keep if has content (even empty string) or tool_calls
            if (msg.role === 'assistant') return msg.content !== undefined || (msg.tool_calls && msg.tool_calls.length > 0);
            // User messages need non-empty content
            if (msg.role === 'user') {
                if (typeof msg.content === 'string') return msg.content.length > 0;
                if (Array.isArray(msg.content)) return msg.content.length > 0;
                return false;
            }
            return true;
        });

        let contextMessages = [...validMessages];

        // Count tokens for system prompt
        let totalTokens = estimateTokens(SYSTEM_PROMPT.content as string);

        // Count all existing context messages
        for (let i = 0; i < contextMessages.length; i++) {
            totalTokens += getMessageTokens(contextMessages[i]);
        }

        // Add the new user message tokens
        const userMessageTokens = getMessageTokens(userMessage);
        totalTokens += userMessageTokens;

        // If we're over limit, remove oldest messages until we fit
        while (totalTokens > MAX_CONTEXT_TOKENS && contextMessages.length > 0) {
            const removedMsg = contextMessages.shift();
            if (removedMsg) {
                totalTokens -= getMessageTokens(removedMsg);
                console.log(`[Context] Removed old message, new total: ${totalTokens} tokens`);
            }
        }

        // Update token count display
        setTokenCount(totalTokens);

        // Track total tokens used in this request for billing
        let sessionTokensUsed = 0;

        // Check if userMessage is already the last message in context (to avoid duplication)
        const lastContextMsg = contextMessages[contextMessages.length - 1];
        const isUserMsgAlreadyInContext = lastContextMsg?.role === 'user' &&
            ((typeof lastContextMsg.content === 'string' && typeof userMessage.content === 'string' &&
                lastContextMsg.content === userMessage.content) ||
                (Array.isArray(lastContextMsg.content) && Array.isArray(userMessage.content)));

        let currentMessages = isUserMsgAlreadyInContext
            ? [...contextMessages]
            : [...contextMessages, userMessage];

        // Track files created in this session to detect loops
        const filesCreatedThisSession = new Set<string>();
        let sameFileCreatedCount = 0;
        let consecutiveErrorCount = 0;
        let editFileFailCount = 0;
        const MAX_CONSECUTIVE_ERRORS = 5;
        const MAX_EDIT_FAILS = 4;

        try {
            // Auto-generate title for new chats (first message only)
            // Uses separate titleGenerator module â€” runs in background, never blocks
            if (currentStoreMessages.length === 1 && user && chatId) {
                const userContentStr = typeof userMessage.content === 'string'
                    ? userMessage.content
                    : (Array.isArray(userMessage.content) ? (userMessage.content.find(c => c.type === 'text') as { type: 'text', text: string } | undefined)?.text || '' : '');

                if (userContentStr) {
                    generateAndSaveTitle(userContentStr, chatId).catch(() => {});
                }
            }

            let turns = 0;
            const MAX_TURNS = 80;

            // Track which tools we've already shown in the UI during this session
            // Maps toolCallId -> actionId (our local UI id)
            // Moved outside while loop so it persists across turns
            const toolIdToActionId = new Map<string, string>();

            while (turns < MAX_TURNS) {
                if (abortControllerRef.current?.signal.aborted) break;

                // Add placeholder for assistant response
                addMessage({ role: 'assistant', content: '' });

                let assistantMessageContent = '';
                let toolCalls: ToolCall[] = [];

                let thinkingContent = '';
                setCurrentThinking('');
                setThinkingDuration(0);

                let thinkingStartTimeLocal: number | null = null;
                let thinkingEndTime: number | null = null;
                let lastThinkingUpdate: number | null = null;

                // Log turn info (simplified)
                console.log(`[Chat] Turn ${turns + 1}/${MAX_TURNS}, sending ${currentMessages.length} messages to AI`);


                const usage = await sendMessage(
                    [SYSTEM_PROMPT, ...currentMessages],
                    selectedModel,
                    apiKey,
                    (content, tools, thinking) => {
                        if (abortControllerRef.current?.signal.aborted) return;

                        // Handle thinking from AI
                        if (thinking) {
                            // Start timing on first thinking chunk
                            if (!thinkingStartTimeLocal) {
                                thinkingStartTimeLocal = Date.now();
                                setThinkingStartTime(thinkingStartTimeLocal);
                            }

                            // Track last update time
                            lastThinkingUpdate = Date.now();

                            // Clean thinking of artifacts
                            let cleanThinking = thinking.replace(/<\|tool_calls_section_begin\|>[\s\S]*/g, '').trim();
                            thinkingContent = cleanThinking;
                            setCurrentThinking(cleanThinking);

                            // Update message immediately with thinking so it renders in-place
                            // This prevents the "jumping" issue by executing standard rendering logic
                            updateLastMessage(assistantMessageContent, toolCalls.length > 0 ? toolCalls : undefined, cleanThinking, undefined);
                        }

                        if (content) {
                            assistantMessageContent += content;

                            // Clean content of artifacts
                            assistantMessageContent = assistantMessageContent.replace(/<\|tool_calls_section_begin\|>[\s\S]*/g, '');

                            // CHECK FOR THINKING TAGS (for models that output <think> inside content)
                            const hasThinkStart = assistantMessageContent.includes('<think>');
                            const hasThinkEnd = assistantMessageContent.includes('</think>');

                            // If we just started a <think> block inside content, START the timer if not running
                            if (hasThinkStart && !hasThinkEnd && !thinkingStartTimeLocal) {
                                thinkingStartTimeLocal = Date.now();
                                setThinkingStartTime(thinkingStartTimeLocal);
                            }

                            // If we hit the end of thinking, STOP the timer
                            if (hasThinkEnd && thinkingStartTimeLocal && !thinkingEndTime) {
                                thinkingEndTime = Date.now();
                                const duration = Math.round((thinkingEndTime - thinkingStartTimeLocal) / 1000);
                                setThinkingDuration(Math.max(1, duration));
                                setThinkingStartTime(null); // Stop live timer logic
                            }

                            // If we have content but NO thinking tags and NO native thinking start, ensure timer is off
                            // (This handles the case where we transition from native thinking to content)
                            if (!hasThinkStart && thinkingStartTimeLocal && !thinkingEndTime && !thinking) {
                                // We were thinking (natively), but now we got content. Stop timer.
                                thinkingEndTime = lastThinkingUpdate || Date.now();
                                const duration = Math.round((thinkingEndTime - thinkingStartTimeLocal) / 1000);
                                setThinkingDuration(Math.max(1, duration));
                                setThinkingStartTime(null);
                            }

                            // Parse thinking - model outputs thinking then </think> then actual response
                            if (hasThinkEnd) {
                                const parts = assistantMessageContent.split('</think>');
                                const thinkingPart = parts[0].replace('<think>', '').trim();
                                let responsePart = parts.slice(1).join('</think>').trim();

                                // Clean tool_call tags from response
                                responsePart = responsePart.replace(/<tool_call>/g, '').trim();

                                if (thinkingPart) {
                                    thinkingContent = thinkingPart;
                                    setCurrentThinking(thinkingPart);
                                    // Final duration available here
                                    const confirmedDuration = thinkingEndTime
                                        ? Math.round((thinkingEndTime - thinkingStartTimeLocal!) / 1000)
                                        : (thinkingDuration || undefined);

                                    updateLastMessage(responsePart, toolCalls.length > 0 ? toolCalls : undefined, thinkingContent, confirmedDuration);
                                } else {
                                    updateLastMessage(responsePart, toolCalls.length > 0 ? toolCalls : undefined, undefined, undefined);
                                }
                            }
                            // Still in think block?
                            else if (hasThinkStart) {
                                const thinking = assistantMessageContent.replace('<think>', '').trim();
                                thinkingContent = thinking;
                                setCurrentThinking(thinking);

                                // Show EMPTY content for message, but update thinking
                                updateLastMessage('', toolCalls.length > 0 ? toolCalls : undefined, thinking, undefined);
                            }
                            // Normal content
                            else {
                                updateLastMessage(assistantMessageContent, toolCalls.length > 0 ? toolCalls : undefined, thinkingContent || undefined, thinkingDuration || undefined);
                            }
                        } else if (tools) {
                            toolCalls = tools;
                            // Ensure all tools are in the UI (some may have been added via streaming already)
                            tools.forEach(tc => {
                                if (!toolIdToActionId.has(tc.id)) {
                                    const displayName = getActionDisplayName(tc.function.name, tc.function.arguments || '');
                                    const id = addAction(tc.function.name, displayName);
                                    toolIdToActionId.set(tc.id, id);
                                    updateAction(id, { status: 'running' });
                                }
                            });

                            updateLastMessage(assistantMessageContent, toolCalls, thinkingContent, thinkingEndTime ? Math.max(1, Math.round((thinkingEndTime - thinkingStartTimeLocal!) / 1000)) : undefined);
                        }
                    },
                    abortControllerRef.current?.signal,
                    (toolName, args, toolId) => {
                        // STREAMING TOOLS CALLBACK - called for each chunk of a tool call
                        if (!toolId) return;

                        if (!toolIdToActionId.has(toolId)) {
                            // New tool detected - add to UI immediately
                            const displayName = getActionDisplayName(toolName, args);
                            const id = addAction(toolName || 'Processing...', displayName);
                            toolIdToActionId.set(toolId, id);
                            updateAction(id, { status: 'running' });
                        } else {
                            // Update existing tool with new info
                            const actionId = toolIdToActionId.get(toolId)!;
                            const displayName = getActionDisplayName(toolName, args);
                            updateAction(actionId, { displayName, toolName: toolName || undefined });
                        }
                    }
                );

                // Final update after stream finishes
                if (thinkingContent) {
                    // Ensure duration is set
                    const finalDuration = thinkingDuration || (thinkingStartTimeLocal ? Math.max(1, Math.round((Date.now() - thinkingStartTimeLocal) / 1000)) : undefined);
                    updateLastMessage(assistantMessageContent, toolCalls.length > 0 ? toolCalls : undefined, thinkingContent, finalDuration);
                }

                setThinkingStartTime(null);

                if (abortControllerRef.current?.signal.aborted) break;

                // Add tokens from this turn to session total
                sessionTokensUsed += usage.total_tokens;

                // Update UI token count
                setTokenCount(sessionTokensUsed);

                // Save tokens to DB immediately
                // Token usage tracking (local only)
                if (user?.uid && usage.total_tokens > 0) {
                    console.log(`[Chat] Tokens: ${usage.prompt_tokens} in + ${usage.completion_tokens} out = ${usage.total_tokens}`);
                }

                // Clean content from think tags for display, but keep thinking for context
                let cleanContent = assistantMessageContent;
                if (cleanContent.includes('</think>')) {
                    cleanContent = cleanContent.split('</think>').slice(1).join('</think>').trim();
                }
                cleanContent = cleanContent.replace(/<think>[\s\S]*?<\/think>\s*/g, '').trim();

                // Clean tool_call tags that some models output incorrectly
                cleanContent = cleanContent.replace(/<tool_call>/g, '').trim();

                // If AI responded with tool_calls but no text on the first turn,
                // add an auto-generated status message so the user sees something
                if (!cleanContent && toolCalls.length > 0) {
                    const toolNames = toolCalls.map(tc => tc.function.name);
                    if (turns === 0) {
                        // First turn â€” show a friendly starting message
                        if (toolNames.includes('runCommand')) {
                            cleanContent = 'âš™ï¸ Setting up the project...';
                        } else if (toolNames.some(n => n === 'createFile' || n === 'batchCreateFiles')) {
                            cleanContent = 'ðŸ”¨ Building the project...';
                        } else if (toolNames.includes('readFile') || toolNames.includes('readMultipleFiles') || toolNames.includes('listFiles')) {
                            cleanContent = 'ðŸ“– Analyzing the project...';
                        } else {
                            cleanContent = 'ðŸš€ Working on it...';
                        }
                    }
                    // Update the UI with this auto-text (even if empty â€” to ensure tool_calls render)
                    updateLastMessage(cleanContent, toolCalls, thinkingContent || undefined, undefined);
                }

                const assistantMessage: Message = {
                    role: 'assistant',
                    content: cleanContent || null,
                    tool_calls: toolCalls.length > 0 ? toolCalls : undefined
                } as any;

                // Store thinking - AI should see its own reasoning for continuity
                if (thinkingContent) {
                    (assistantMessage as any).thinking = thinkingContent;
                }

                // Store thinking separately (not sent to API but shown in UI)
                if (thinkingContent) {
                    (assistantMessage as any).thinking = thinkingContent;
                }

                // Message is already in store via updateLastMessage, just add to context
                currentMessages.push(assistantMessage);

                if (toolCalls.length === 0) {
                    // No tool calls - AI is done or just responded with text
                    console.log('[Chat] AI response (no tool calls):', cleanContent?.slice(0, 200));
                    console.log('[Chat] Done - no tool calls received, ending loop');
                    break;
                }

                // If AI responded with only empty content and no tool calls on a non-first turn,
                // it might be confused. Log it.
                if (!cleanContent && toolCalls.length > 0) {
                    console.log(`[Chat] Turn ${turns + 1}: AI sent ${toolCalls.length} tool calls without text`);
                }

                console.log(`[Chat] Running ${toolCalls.length} tool(s)...`);
                let devServerStarted = false;

                for (let i = 0; i < toolCalls.length; i++) {
                    const toolCall = toolCalls[i];
                    if (abortControllerRef.current?.signal.aborted) break;

                    // Ensure action exists for this tool call
                    if (!toolIdToActionId.has(toolCall.id)) {
                        const displayName = getActionDisplayName(toolCall.function.name, toolCall.function.arguments || '');
                        const id = addAction(toolCall.function.name, displayName);
                        toolIdToActionId.set(toolCall.id, id);
                    }

                    // Get action ID by tool call ID (reliable mapping)
                    const actionId = toolIdToActionId.get(toolCall.id);

                    // Set THIS action to 'running' and yield so React paints it
                    if (actionId) {
                        updateAction(actionId, { status: 'running' });
                    }
                    await new Promise(r => requestAnimationFrame(r));

                    // Check for duplicate file creation (loop detection)
                    if (toolCall.function.name === 'createFile') {
                        try {
                            const args = JSON.parse(toolCall.function.arguments || '{}');
                            if (args.path && filesCreatedThisSession.has(args.path)) {
                                sameFileCreatedCount++;
                                console.log(`[Chat] Warning: ${args.path} already created this session (count: ${sameFileCreatedCount})`);
                                if (sameFileCreatedCount >= 5) {
                                    console.log('[Chat] Loop detected - same file created multiple times, breaking');
                                    devServerStarted = true;
                                    break;
                                }
                            }
                            filesCreatedThisSession.add(args.path);
                        } catch { }
                    }

                    let result = '';
                    try {
                        result = await handleToolCall(toolCall);
                    } catch (err: any) {
                        console.error('Tool execution error:', err);
                        result = `Error executing tool ${toolCall.function.name}: ${err.message}.\n\nâš ï¸ Suggestion: Try a different approach or use readFile to check the current state.`;
                    }

                    // Update action status to done or error
                    if (actionId) {
                        // Only mark as error if it's a real tool failure, not informational output
                        const isToolError = (
                            result.startsWith('Error ') ||
                            result.startsWith('[SYSTEM] âŒ') ||
                            result.includes('crashed') ||
                            result.includes('FAILED')
                        ) && !result.includes('[SYSTEM] âœ…') && !result.includes('TypeScript check found');

                        const newStatus = isToolError ? 'error' : 'done';
                        console.log(`[Actions] ${toolCall.function.name} (${actionId}) â†’ ${newStatus}`);
                        updateAction(actionId, {
                            status: newStatus,
                            result,
                            args: toolCall.function.arguments || ''
                        });

                        // Track consecutive errors for loop detection
                        if (isToolError) {
                            consecutiveErrorCount++;
                            if (toolCall.function.name === 'editFile') {
                                editFileFailCount++;
                            }
                        } else {
                            consecutiveErrorCount = 0; // Reset on success
                        }
                    } else {
                        console.warn(`[Actions] No actionId found for toolCall ${toolCall.id}`);
                    }

                    const toolMessage: Message = {
                        role: 'tool',
                        tool_call_id: toolCall.id,
                        name: toolCall.function.name,
                        content: result
                    };

                    addMessage(toolMessage);
                    currentMessages.push(toolMessage);

                    // Check if dev server was started
                    if (result.includes('DEV SERVER IS NOW RUNNING')) {
                        devServerStarted = true;
                    }
                }

                // If dev server started, let AI know but don't force-break
                // AI should naturally stop after seeing the server is running
                if (devServerStarted) {
                    console.log('[Chat] Dev server started');

                    // Inject a system hint so AI knows to wrap up
                    const devServerHint: Message = {
                        role: 'system',
                        content: 'âœ… DEV SERVER IS NOW RUNNING. The preview is available. If there are no errors to fix, tell the user the project is ready and STOP calling tools.'
                    };
                    currentMessages.push(devServerHint);
                    // Don't break â€” let AI do one more turn to provide a summary
                }

                // Loop detection: too many consecutive errors
                if (consecutiveErrorCount >= MAX_CONSECUTIVE_ERRORS) {
                    console.log(`[Chat] Loop detected: ${consecutiveErrorCount} consecutive errors, injecting recovery hint`);
                    const recoveryMessage: Message = {
                        role: 'system',
                        content: `âš ï¸ LOOP DETECTED: ${consecutiveErrorCount} consecutive tool errors. STOP and change your approach:\n1. Use getErrors() to see all current errors\n2. Use readFile() to check the actual file content\n3. If editFile keeps failing, use createFile to rewrite the entire file\n4. If pnpm install fails, check the package name with searchWeb\n5. Take a step back and think about what's actually wrong`
                    };
                    currentMessages.push(recoveryMessage);
                    addMessage(recoveryMessage);
                    consecutiveErrorCount = 0; // Reset to give AI another chance
                }

                // Loop detection: editFile keeps failing
                if (editFileFailCount >= MAX_EDIT_FAILS) {
                    console.log(`[Chat] editFile loop detected: ${editFileFailCount} failures, injecting hint`);
                    const editHint: Message = {
                        role: 'system',
                        content: `âš ï¸ editFile has failed ${editFileFailCount} times. STOP using editFile for this file. Use createFile to rewrite the entire file instead. Call readFile first to see the current content, then createFile with the complete updated content.`
                    };
                    currentMessages.push(editHint);
                    addMessage(editHint);
                    editFileFailCount = 0;
                }

                turns++;
            }

            // Smart AI-powered context compression
            const allMessages = useStore.getState().messages;

            let totalTokens = estimateTokens(SYSTEM_PROMPT.content as string);
            allMessages.forEach(msg => {
                totalTokens += getMessageTokens(msg);
            });

            const modelContextLimit = useStore.getState().modelContextLimit || 200000;
            const MAX_CONTEXT_TOKENS = Math.floor(modelContextLimit * 0.8);
            const COMPRESSION_THRESHOLD = Math.floor(MAX_CONTEXT_TOKENS * 0.8); // 80% of limit

            // Check if we need compression
            if (totalTokens > COMPRESSION_THRESHOLD && allMessages.length > 10) {
                console.log(`[Context] Tokens: ${totalTokens}/${MAX_CONTEXT_TOKENS}, triggering AI compression...`);

                try {
                    // How many messages to keep uncompressed (recent context)
                    const KEEP_RECENT = 8;
                    const messagesToCompress = allMessages.slice(0, -KEEP_RECENT);
                    const recentMessages = allMessages.slice(-KEEP_RECENT);


                    // Create a simple summary (AI summarization would require recursive call)
                    const firstUserMsg = messagesToCompress.find(m => m.role === 'user');
                    const summary = `Previous conversation: ${firstUserMsg ? (typeof firstUserMsg.content === 'string' ? firstUserMsg.content.substring(0, 100) : 'User started conversation') : 'Earlier messages'}... (${messagesToCompress.length} messages compressed to save context)`;

                    // Create summary message
                    const summaryMessage: Message = {
                        role: 'system',
                        content: `ðŸ“ ${summary}`
                    };

                    // Replace old messages with summary + keep recent
                    const compressedContext = [summaryMessage, ...recentMessages];
                    setMessages(compressedContext);

                    // Recalculate tokens
                    let newTotal = estimateTokens(SYSTEM_PROMPT.content as string);
                    compressedContext.forEach(msg => {
                        newTotal += getMessageTokens(msg);
                    });

                    setTokenCount(newTotal);

                    // Show notification
                    const compressionNotice: Message = {
                        role: 'assistant',
                        content: `ðŸ—œï¸ Context compressed by AI: ${messagesToCompress.length} old messages summarized. Freed ${totalTokens - newTotal} tokens. Current: ${newTotal.toLocaleString()}/${MAX_CONTEXT_TOKENS.toLocaleString()}`
                    };
                    addMessage(compressionNotice);

                    console.log(`[Context] Compressed ${messagesToCompress.length} messages, saved ${totalTokens - newTotal} tokens`);
                } catch (err) {
                    console.error('[Context] AI compression failed, falling back to simple removal:', err);

                    // Fallback: simple removal of oldest messages
                    let compressedMessages = [...allMessages];
                    let removedCount = 0;

                    while (totalTokens > MAX_CONTEXT_TOKENS && compressedMessages.length > 5) {
                        const removed = compressedMessages.shift();
                        if (removed) {
                            totalTokens -= getMessageTokens(removed);
                            removedCount++;
                        }
                    }

                    if (removedCount > 0) {
                        setMessages(compressedMessages);
                        setTokenCount(totalTokens);

                        const fallbackNotice: Message = {
                            role: 'assistant',
                            content: `ðŸ—œï¸ Context compressed: ${removedCount} old messages removed. Current: ${totalTokens.toLocaleString()}/${MAX_CONTEXT_TOKENS.toLocaleString()}`
                        };
                        addMessage(fallbackNotice);
                    }
                }
            } else {
                // Just update the token count
                setTokenCount(totalTokens);
            }

        } catch (error: any) {
            if (abortControllerRef.current?.signal.aborted) {
                // When stopped, check if last message has incomplete tool_calls
                const state = useStore.getState();
                const lastMsg = state.messages[state.messages.length - 1] as any;

                if (lastMsg?.role === 'assistant' && lastMsg?.tool_calls?.length > 0) {
                    // Add placeholder tool responses for incomplete tool calls
                    for (const tc of lastMsg.tool_calls) {
                        // Check if tool response already exists
                        const hasResponse = state.messages.some(
                            (m: any) => m.role === 'tool' && m.tool_call_id === tc.id
                        );
                        if (!hasResponse) {
                            addMessage({
                                role: 'tool',
                                tool_call_id: tc.id,
                                name: tc.function.name,
                                content: '[Stopped by user]'
                            });
                        }
                    }
                }

                // Update the empty placeholder instead of adding a new message
                const stateAfter = useStore.getState();
                const last = stateAfter.messages[stateAfter.messages.length - 1];
                if (last?.role === 'assistant' && !last.content && !last.tool_calls?.length) {
                    updateLastMessage('Stopped by user.');
                } else {
                    addMessage({ role: 'assistant', content: 'Stopped by user.' });
                }
            } else {
                console.error('[Chat] Error:', error);
                const errorMessage = error?.message || 'Failed to get response';

                // Same check for errors
                const state = useStore.getState();
                const lastMsg = state.messages[state.messages.length - 1] as any;

                if (lastMsg?.role === 'assistant' && lastMsg?.tool_calls?.length > 0) {
                    for (const tc of lastMsg.tool_calls) {
                        const hasResponse = state.messages.some(
                            (m: any) => m.role === 'tool' && m.tool_call_id === tc.id
                        );
                        if (!hasResponse) {
                            addMessage({
                                role: 'tool',
                                tool_call_id: tc.id,
                                name: tc.function.name,
                                content: `[Error: ${errorMessage}]`
                            });
                        }
                    }
                }

                // Update empty placeholder instead of adding new message
                const stateAfter = useStore.getState();
                const last = stateAfter.messages[stateAfter.messages.length - 1];
                if (last?.role === 'assistant' && !last.content && !last.tool_calls?.length) {
                    updateLastMessage(`Error: ${errorMessage}`);
                } else {
                    addMessage({ role: 'assistant', content: `Error: ${errorMessage}` });
                }
            }
        } finally {
            setIsLoading(false);
            abortControllerRef.current = null;
            setCurrentThinking('');

            // Clear actions after a delay to allow smooth transition to completed state
            setTimeout(() => setActions([]), 500);

            if (chatId && user) {
                try {
                    const { useStore } = await import('../store');
                    const state = useStore.getState();

                    await saveChatMessages(chatId, state.messages);

                    if (Object.keys(state.files).length > 0) {
                        await saveProject(chatId, user.uid, state.files);
                    }


                } catch {
                    // Ignore save errors
                }
            }
        }
    };

    // Form submit handler
    const handleSubmit = async (e: React.FormEvent) => {
        e.preventDefault();
        if ((!input.trim() && selectedImages.length === 0 && selectedDocuments.length === 0) || isLoading) return;

        // Create chat if not exists
        let chatId = currentChatId;
        if (!chatId && user) {
            try {
                const title = input.slice(0, 50) + (input.length > 50 ? '...' : '');
                const chat = await createChat(user.uid, title);
                chatId = chat.id;
                setCurrentChatId(chat.id);
                navigate(`/c/${chat.id}`, { replace: true });

                // Update chats in store so titleGenerator can find this chat
                const currentChats = useStore.getState().chats;
                useStore.getState().setChats([chat, ...currentChats]);
            } catch (err) {
                console.error('Failed to create chat:', err);
                return;
            }
        }

        // Build AI message (what AI receives) - full file contents
        let aiText = input;

        // Capture selected element before clearing
        const pickedElementForSend = selectedElement ? { ...selectedElement } : null;

        // Prepend selected element context if user picked an element from preview
        if (pickedElementForSend) {
            aiText = `[User selected this element from the preview]\nElement: ${pickedElementForSend.tag}\nSelector: ${pickedElementForSend.selector}\nText content: "${pickedElementForSend.text}"\n\nUser request: ${aiText}`;
            setSelectedElement(null); // Clear after sending
        }

        if (selectedDocuments.length > 0) {
            const docsContext = selectedDocuments.map(doc =>
                `\n\n[User attached file: ${doc.name}]\n\`\`\`${doc.type.split('/')[1] || 'text'}\n${doc.content}\n\`\`\``
            ).join('');
            aiText = input + docsContext;
        }

        // Message for display (stored in state) - just user text, attachments stored separately
        let displayMessage: any;
        if (selectedImages.length > 0) {
            displayMessage = {
                role: 'user',
                content: [
                    { type: 'text', text: input },
                    ...selectedImages.map(img => ({ type: 'image_url' as const, image_url: { url: img } }))
                ]
            };
        } else {
            displayMessage = { role: 'user', content: input };
        }

        // Save picked element info for display in chat
        if (pickedElementForSend) {
            displayMessage.pickedElement = pickedElementForSend;
        }

        // Add attachments with content to display message (for transfer to workbench)
        if (selectedDocuments.length > 0) {
            displayMessage.attachments = selectedDocuments.map(doc => ({
                name: doc.name,
                type: doc.type,
                size: doc.content.length,
                content: doc.content
            }));
        }

        // Message for AI (with full file contents)
        let aiMessage: Message;
        if (selectedImages.length > 0) {
            aiMessage = {
                role: 'user',
                content: [
                    { type: 'text', text: aiText },
                    ...selectedImages.map(img => ({ type: 'image_url' as const, image_url: { url: img } }))
                ]
            };
        } else {
            aiMessage = { role: 'user', content: aiText };
        }

        addMessage(displayMessage);
        setInput('');
        setSelectedImages([]);
        setSelectedDocuments([]);
        if (textareaRef.current) {
            textareaRef.current.style.height = 'auto';
        }

        // Send AI message (with full file contents) to AI
        await triggerAIResponse(aiMessage, chatId || undefined);
    };

    const [showModelMenu, setShowModelMenu] = useState(false);

    const markdownComponents = React.useMemo(() => ({
        code({ node, inline, className, children, ...props }: any) {
            const match = /language-([\w-]+)/.exec(className || '');
            if (!inline && match && match[1] === 'mermaid') {
                return <MermaidBlock code={String(children).replace(/\n$/, '')} isDark={isDark} />;
            }
            // Search results block removed - don't render it
            if (!inline && match && match[1] === 'search-results') {
                return null;
            }
            return <code className={className} {...props}>{children}</code>;
        },
        img({ src, alt, ...props }: any) {
            // Use ImageViewer for fullscreen capability
            if (src) {
                return <ImageViewer src={src} alt={alt} isDark={isDark} />;
            }
            return <img src={src} alt={alt} {...props} />;
        }
    }), [isDark]);

    return (
        <div className={`flex flex-col h-full ${isDark ? 'bg-[#141414]' : 'bg-white'}`}>
            {/* Messages Area */}
            <div
                ref={scrollRef}
                onScroll={onScroll}
                className="flex-1 overflow-y-auto scrollbar-hide"
            >
                <div className="max-w-2xl mx-auto px-6 py-6 space-y-5">
                    {groupedMessages.map((group, idx) => (
                        <div key={idx} className="space-y-3 animate-fade-in-up">
                            {group.role === 'assistant' && group.thinking && (
                                <ThinkingBlock
                                    thinking={group.thinking}
                                    isDark={isDark}
                                    thinkingTime={group.thinkingDuration || undefined}
                                    startTime={idx === groupedMessages.length - 1 && isLoading ? thinkingStartTime : undefined}
                                />
                            )}

                            {group.role === 'user' && group.attachments && group.attachments.length > 0 && (
                                <div className="flex justify-end mb-1">
                                    <div className="flex flex-col gap-1.5">
                                        {group.attachments.map((file, i) => (
                                            <FileAttachmentBlock key={i} file={file} isDark={isDark} />
                                        ))}
                                    </div>
                                </div>
                            )}

                            {/* Render segments in order for assistant messages */}
                            {group.role === 'assistant' && group.segments && group.segments.length > 0 ? (
                                <>
                                    {group.segments.map((seg, segIdx) => {
                                        if (seg.type === 'text' && seg.content) {
                                            const textContent = typeof seg.content === 'string' ? seg.content : '';
                                            if (!textContent) return null;
                                            return (
                                                <div key={`seg-${segIdx}`} className="flex justify-start">
                                                    <div className={`text-[14px] leading-relaxed ${isDark ? 'text-[#e5e5e5] max-w-full' : 'text-gray-800 max-w-full'}`}>
                                                        <div className={`prose prose-sm max-w-none ${isDark ? 'prose-invert prose-pre:bg-[#1a1a1a] prose-pre:border prose-pre:border-[#2a2a2a] prose-pre:rounded-lg prose-code:text-[#e5e5e5]' : 'prose-pre:bg-gray-50 prose-pre:border prose-pre:border-gray-200 prose-pre:rounded-lg'}`}>
                                                            <ReactMarkdown remarkPlugins={[remarkGfm]} components={markdownComponents}>
                                                                {textContent.replace(/^\[SYSTEM\] .*/gm, '')}
                                                            </ReactMarkdown>
                                                        </div>
                                                    </div>
                                                </div>
                                            );
                                        }
                                        if (seg.type === 'tools' && seg.toolCalls && seg.toolCalls.length > 0) {
                                            // If this is the last segment and we're live, show live actions
                                            const isLastSegment = segIdx === group.segments!.length - 1;
                                            const showLive = isLoading && isLastSegment && idx === groupedMessages.length - 1 && actions.length > 0;

                                            if (showLive) {
                                                return <ActionsList key={`seg-${segIdx}`} actions={actions.filter(a => a.toolName !== 'drawDiagram')} isLive={true} isDark={isDark} />;
                                            }
                                            return (
                                                <ActionsList
                                                    key={`seg-${segIdx}`}
                                                    actions={seg.toolCalls.filter(tc => tc.call.function.name !== 'drawDiagram').map((tc, i) => ({
                                                        id: `completed_${idx}_${segIdx}_${i}`,
                                                        toolName: tc.call.function.name,
                                                        displayName: getActionDisplayName(tc.call.function.name, tc.call.function.arguments || ''),
                                                        status: tc.result?.startsWith('Error') ? 'error' as const : 'done' as const,
                                                        result: tc.result,
                                                        args: tc.call.function.arguments || ''
                                                    }))}
                                                    isDark={isDark}
                                                />
                                            );
                                        }
                                        return null;
                                    })}
                                    {/* Live actions if no segments have tools yet */}
                                    {isLoading && idx === groupedMessages.length - 1 && actions.length > 0 && !group.segments.some(s => s.type === 'tools') && (
                                        <ActionsList actions={actions.filter(a => a.toolName !== 'drawDiagram')} isLive={true} isDark={isDark} />
                                    )}
                                </>
                            ) : (
                                <>
                                    {/* Fallback: user messages or assistant without segments */}
                                    <div className={`flex ${group.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                                        <div
                                            className={`text-[14px] leading-relaxed ${group.role === 'user'
                                                ? isDark ? 'bg-[#1f1f1f] text-[#e5e5e5] rounded-2xl px-4 py-2.5 max-w-[85%]' : 'bg-gray-100 text-gray-900 rounded-2xl px-4 py-2.5 max-w-[85%]'
                                                : isDark ? 'text-[#e5e5e5] max-w-full' : 'text-gray-800 max-w-full'
                                                }`}
                                        >
                                            {/* Picked element indicator */}
                                            {group.role === 'user' && (group as any).pickedElement && (
                                                <div className={`flex items-center gap-1.5 mb-2 text-xs ${isDark ? 'text-blue-400/70' : 'text-blue-500/70'}`}>
                                                    <MousePointer2 className="w-3 h-3 flex-shrink-0" />
                                                    <span className="font-medium">
                                                        {(group as any).pickedElement.selector.split('.')[0].split('#')[0].toUpperCase()}
                                                    </span>
                                                    {(group as any).pickedElement.text && (
                                                        <span className="truncate opacity-70">
                                                            {(group as any).pickedElement.text.length > 30
                                                                ? (group as any).pickedElement.text.slice(0, 30) + 'â€¦'
                                                                : (group as any).pickedElement.text}
                                                        </span>
                                                    )}
                                                </div>
                                            )}
                                            {group.content && (
                                                <div className={`prose prose-sm max-w-none ${isDark ? 'prose-invert prose-pre:bg-[#1a1a1a] prose-pre:border prose-pre:border-[#2a2a2a] prose-pre:rounded-lg prose-code:text-[#e5e5e5]' : 'prose-pre:bg-gray-50 prose-pre:border prose-pre:border-gray-200 prose-pre:rounded-lg'}`}>
                                                    {Array.isArray(group.content) ? (
                                                        <div className="space-y-2">
                                                            {group.content.map((part, i) => {
                                                                if (part.type === 'image_url') {
                                                                    return <img key={i} src={part.image_url.url} alt="" className="max-w-full rounded-lg max-h-[250px] object-contain" />;
                                                                }
                                                                return <ReactMarkdown key={i} remarkPlugins={[remarkGfm]} components={markdownComponents}>{part.text.replace(/^\[SYSTEM\] .*/gm, '')}</ReactMarkdown>;
                                                            })}
                                                        </div>
                                                    ) : (
                                                        <ReactMarkdown remarkPlugins={[remarkGfm]} components={markdownComponents}>
                                                            {group.content.replace(/^\[SYSTEM\] .*/gm, '')}
                                                        </ReactMarkdown>
                                                    )}
                                                </div>
                                            )}
                                        </div>
                                    </div>
                                    {/* Live actions for assistant without segments */}
                                    {group.role === 'assistant' && isLoading && idx === groupedMessages.length - 1 && actions.length > 0 && (
                                        <ActionsList actions={actions.filter(a => a.toolName !== 'drawDiagram')} isLive={true} isDark={isDark} />
                                    )}
                                </>
                            )}
                        </div>
                    ))}

                    {/* Live Thinking - only when there's no assistant message yet or its thinking isn't set */}
                    {isLoading && currentThinking && (!groupedMessages.length || groupedMessages[groupedMessages.length - 1].role !== 'assistant' || !groupedMessages[groupedMessages.length - 1].thinking) && (
                        <ThinkingBlock thinking={currentThinking} isDark={isDark} thinkingTime={thinkingDuration || undefined} startTime={thinkingStartTime} />
                    )}

                    {/* Live Actions - only show here if there's no assistant message group yet */}
                    {isLoading && actions.length > 0 && (!groupedMessages.length || groupedMessages[groupedMessages.length - 1].role !== 'assistant') && (
                        <ActionsList actions={actions.filter(a => a.toolName !== 'drawDiagram')} isLive={true} isDark={isDark} />
                    )}

                    {/* Typing indicator â€” shows when AI is loading but hasn't produced any visible content yet */}
                    {isLoading && !currentThinking && actions.length === 0 && (
                        !groupedMessages.length ||
                        groupedMessages[groupedMessages.length - 1].role === 'user' ||
                        (groupedMessages[groupedMessages.length - 1].role === 'assistant' && !groupedMessages[groupedMessages.length - 1].content)
                    ) && (
                        <div className="flex justify-start animate-fade-in-up">
                            <div className={`flex items-center gap-1.5 px-4 py-3 rounded-2xl ${isDark ? 'text-[#888]' : 'text-gray-400'}`}>
                                <span className="w-2 h-2 rounded-full bg-current animate-bounce" style={{ animationDelay: '0ms' }} />
                                <span className="w-2 h-2 rounded-full bg-current animate-bounce" style={{ animationDelay: '150ms' }} />
                                <span className="w-2 h-2 rounded-full bg-current animate-bounce" style={{ animationDelay: '300ms' }} />
                            </div>
                        </div>
                    )}

                    <div ref={messagesEndRef} />
                </div>
            </div>

            {/* Input Area - centered with margins */}
            <div className="px-4 pb-4">
                <div className={`max-w-[720px] mx-auto rounded-2xl ${isDark ? 'bg-[#1a1a1a] border border-[#2a2a2a]' : 'bg-gray-50 border border-gray-200'}`}>
                    <form
                        onSubmit={handleSubmit}
                        onPaste={handlePaste}
                        onDrop={handleDrop}
                        onDragOver={(e) => e.preventDefault()}
                        className="flex flex-col"
                    >
                        <input
                            type="file"
                            ref={fileInputRef}
                            className="hidden"
                            accept="image/*"
                            multiple
                            onChange={handleImageSelect}
                        />
                        <input
                            type="file"
                            ref={documentInputRef}
                            className="hidden"
                            accept=".txt,.md,.json,.js,.ts,.tsx,.jsx,.css,.html,.py,.java,.c,.cpp,.rs,.go,.sql,.yaml,.yml,.xml,.csv,.log,.sh,.bat,.env,.gitignore"
                            multiple
                            onChange={handleDocumentSelect}
                        />

                        {(selectedImages.length > 0 || selectedDocuments.length > 0) && (
                            <div className={`flex gap-2 px-3 py-2 overflow-x-auto border-b ${isDark ? 'border-[#2a2a2a]' : 'border-gray-200'}`}>
                                {selectedImages.map((img, i) => (
                                    <div key={`img-${i}`} className="relative flex-shrink-0 group">
                                        <img src={img} alt="" className="h-10 w-10 object-cover rounded-lg" />
                                        <button type="button" onClick={() => setSelectedImages(prev => prev.filter((_, idx) => idx !== i))}
                                            className="absolute -top-1 -right-1 bg-red-500 text-white rounded-full p-0.5 opacity-0 group-hover:opacity-100 transition-opacity">
                                            <X className="w-2.5 h-2.5" />
                                        </button>
                                    </div>
                                ))}
                                {selectedDocuments.map((doc, i) => (
                                    <div key={`doc-${i}`} className={`relative flex-shrink-0 group h-10 px-2 rounded-lg flex items-center gap-1.5 ${isDark ? 'bg-[#1f1f1f]' : 'bg-gray-100'}`}>
                                        <FileCode className="w-3.5 h-3.5 text-[#555]" />
                                        <span className={`text-[11px] truncate max-w-[60px] ${isDark ? 'text-[#999]' : 'text-gray-600'}`}>{doc.name}</span>
                                        <button type="button" onClick={() => setSelectedDocuments(prev => prev.filter((_, idx) => idx !== i))}
                                            className="absolute -top-1 -right-1 bg-red-500 text-white rounded-full p-0.5 opacity-0 group-hover:opacity-100 transition-opacity">
                                            <X className="w-2.5 h-2.5" />
                                        </button>
                                    </div>
                                ))}
                            </div>
                        )}

                        {/* Selected element from preview picker */}
                        {selectedElement && (
                            <div className={`flex items-center gap-2 px-3 py-2 border-b ${isDark ? 'border-[#2a2a2a]' : 'border-gray-200'}`}>
                                <div className={`flex items-center gap-2 px-2.5 py-1.5 rounded-lg text-xs max-w-full overflow-hidden ${isDark ? 'bg-blue-500/10 border border-blue-500/20' : 'bg-blue-50 border border-blue-200'}`}>
                                    <MousePointer2 className={`w-3 h-3 flex-shrink-0 ${isDark ? 'text-blue-400' : 'text-blue-500'}`} />
                                    <span className={`font-medium flex-shrink-0 ${isDark ? 'text-blue-400' : 'text-blue-600'}`}>
                                        {selectedElement.selector.split('.')[0].split('#')[0].toUpperCase()}
                                    </span>
                                    {selectedElement.text && (
                                        <span className={`truncate ${isDark ? 'text-zinc-400' : 'text-gray-500'}`}>
                                            {selectedElement.text.length > 40 ? selectedElement.text.slice(0, 40) + 'â€¦' : selectedElement.text}
                                        </span>
                                    )}
                                    <button
                                        type="button"
                                        onClick={() => setSelectedElement(null)}
                                        className={`ml-auto flex-shrink-0 p-0.5 rounded hover:bg-red-500/20 ${isDark ? 'text-zinc-500 hover:text-red-400' : 'text-gray-400 hover:text-red-500'}`}
                                    >
                                        <X className="w-3 h-3" />
                                    </button>
                                </div>
                            </div>
                        )}

                        {/* Textarea area */}
                        <textarea
                            ref={textareaRef}
                            value={input}
                            onChange={(e) => {
                                setInput(e.target.value);
                                // Auto-resize
                                const target = e.target as HTMLTextAreaElement;
                                target.style.height = 'auto';
                                target.style.height = `${Math.min(target.scrollHeight, 250)}px`;
                            }}
                            placeholder="How can Glovix help you today?"
                            className={`w-full bg-transparent text-[13px] px-4 pt-4 pb-2 focus:outline-none resize-none overflow-y-auto ${isDark ? 'text-[#e5e5e5] placeholder:text-[#555]' : 'text-gray-900 placeholder:text-gray-400'}`}
                            style={{ height: 'auto', minHeight: '44px', maxHeight: '250px' }}
                            onKeyDown={(e) => {
                                if (e.key === 'Enter' && !e.shiftKey) {
                                    e.preventDefault();
                                    handleSubmit(e);
                                }
                            }}
                        />

                        {/* Bottom toolbar - separate from textarea */}
                        <div className="flex items-center justify-between px-3 py-2">
                            <div className="flex items-center gap-1.5 relative">
                                <button type="button" onClick={() => setShowModelMenu(!showModelMenu)}
                                    className={`p-1.5 rounded-md transition-colors ${isDark ? 'text-[#444] hover:text-[#888] hover:bg-[#1f1f1f]' : 'text-gray-300 hover:text-gray-500 hover:bg-gray-100'}`}>
                                    <Plus className="w-4 h-4" />
                                </button>

                                {showModelMenu && (
                                    <div className={`absolute bottom-full left-0 mb-1 rounded-lg overflow-hidden z-10 min-w-[160px] ${isDark ? 'bg-[#1a1a1a] border border-[#2a2a2a]' : 'bg-white border border-gray-200 shadow-lg'}`}>
                                        <div className="p-1">
                                            <button type="button" onClick={() => { fileInputRef.current?.click(); setShowModelMenu(false); }}
                                                className={`w-full text-left px-2.5 py-1.5 text-[12px] flex items-center gap-2 rounded ${isDark ? 'hover:bg-[#1f1f1f] text-[#ccc]' : 'hover:bg-gray-50 text-gray-700'}`}>
                                                <ImageIcon className="w-3.5 h-3.5" /> Image
                                            </button>
                                            <button type="button" onClick={() => { documentInputRef.current?.click(); setShowModelMenu(false); }}
                                                className={`w-full text-left px-2.5 py-1.5 text-[12px] flex items-center gap-2 rounded ${isDark ? 'hover:bg-[#1f1f1f] text-[#ccc]' : 'hover:bg-gray-50 text-gray-700'}`}>
                                                <FileCode className="w-3.5 h-3.5" /> Document
                                            </button>
                                        </div>
                                    </div>
                                )}

                                {/* Context indicator button */}
                                <div className="relative group">
                                    <button
                                        type="button"
                                        className={`p-1.5 rounded-md transition-colors ${isDark ? 'text-[#444] hover:text-[#888] hover:bg-[#1f1f1f]' : 'text-gray-300 hover:text-gray-500 hover:bg-gray-100'}`}
                                    >
                                        <svg className="w-4 h-4" fill="none" stroke="currentColor" strokeWidth={2} viewBox="0 0 24 24">
                                            <path strokeLinecap="round" strokeLinejoin="round" d="M20 7l-8-4-8 4m16 0l-8 4m8-4v10l-8 4m0-10L4 7m8 4v10M4 7v10l8 4" />
                                        </svg>
                                    </button>

                                    {/* Tooltip on hover */}
                                    <div className={`absolute bottom-full left-0 mb-2 opacity-0 pointer-events-none group-hover:opacity-100 transition-opacity z-20`}>
                                        <div className={`px-3 py-2 rounded-lg shadow-lg whitespace-nowrap ${isDark ? 'bg-[#1a1a1a] border border-[#2a2a2a]' : 'bg-white border border-gray-200'}`}>
                                            <div className={`text-xs mb-1.5 ${isDark ? 'text-[#888]' : 'text-gray-500'}`}>Context Usage</div>
                                            <div className="flex items-center gap-2">
                                                <div className="relative w-24 h-1.5 bg-gray-200 dark:bg-[#2a2a2a] rounded-full overflow-hidden">
                                                    <div
                                                        className={`h-full transition-all ${(tokenCount / (modelContextLimit * 0.8)) > 0.9
                                                            ? 'bg-red-500'
                                                            : (tokenCount / (modelContextLimit * 0.8)) > 0.7
                                                                ? 'bg-yellow-500'
                                                                : 'bg-green-500'
                                                            }`}
                                                        style={{ width: `${Math.min(100, (tokenCount / (modelContextLimit * 0.8)) * 100)}%` }}
                                                    />
                                                </div>
                                                <span className={`text-xs tabular-nums font-medium ${isDark ? 'text-white' : 'text-gray-900'}`}>
                                                    {tokenCount.toLocaleString()} / {Math.floor(modelContextLimit * 0.8).toLocaleString()}
                                                </span>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div className="flex items-center gap-1">
                                {isLoading ? (
                                    <button
                                        type="button"
                                        onClick={handleStop}
                                        className={`w-8 h-8 flex items-center justify-center rounded-full transition-all ${isDark ? 'bg-white hover:bg-gray-200' : 'bg-black hover:bg-gray-800'}`}
                                    >
                                        <div className={`w-3 h-3 rounded-sm ${isDark ? 'bg-black' : 'bg-white'}`} />
                                    </button>
                                ) : (
                                    <button type="submit" disabled={!input.trim() && selectedImages.length === 0}
                                        className={`w-8 h-8 flex items-center justify-center rounded-full disabled:opacity-30 disabled:cursor-not-allowed transition-all ${isDark ? 'bg-white text-black hover:bg-gray-200' : 'bg-black text-white hover:bg-gray-800'}`}>
                                        <svg className="w-4 h-4" fill="none" stroke="currentColor" strokeWidth={2.5} viewBox="0 0 24 24">
                                            <path strokeLinecap="round" strokeLinejoin="round" d="M5 10l7-7m0 0l7 7m-7-7v18" />
                                        </svg>
                                    </button>
                                )}
                            </div>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    );
}

function ThinkingBlock({ thinking, isDark, thinkingTime, startTime }: { thinking: string; isDark: boolean; thinkingTime?: number, startTime?: number | null }) {
    const [isExpanded, setIsExpanded] = useState(false);
    const [elapsed, setElapsed] = useState(0);

    useEffect(() => {
        if (startTime && !thinkingTime) {
            // Initial calc
            setElapsed(Math.max(1, Math.round((Date.now() - startTime) / 1000)));

            const interval = setInterval(() => {
                setElapsed(Math.max(1, Math.round((Date.now() - startTime) / 1000)));
            }, 1000);
            return () => clearInterval(interval);
        }
    }, [startTime, thinkingTime]);

    if (!thinking) return null;

    // Use finalized time if available, otherwise live elapsed time
    const displayTime = thinkingTime !== undefined ? thinkingTime : (startTime ? elapsed : 0);

    return (
        <div className="mb-2 animate-fade-in">
            <button
                onClick={() => setIsExpanded(!isExpanded)}
                className={`flex items-center gap-1.5 text-sm transition-colors ${isDark ? 'text-[#666] hover:text-[#888]' : 'text-gray-400 hover:text-gray-600'}`}
            >
                <span>Thought for {displayTime}s</span>
                <ChevronRight className={`w-3.5 h-3.5 transition-transform ${isExpanded ? 'rotate-90' : ''}`} />
            </button>

            {isExpanded && (
                <div className={`mt-2 text-sm leading-relaxed whitespace-pre-wrap animate-fade-in ${isDark ? 'text-[#555]' : 'text-gray-400'}`}>
                    {thinking}
                </div>
            )}
        </div>
    );
}

function FileAttachmentBlock({ file, isDark }: { file: FileAttachment; isDark: boolean }) {
    const [showMenu, setShowMenu] = useState(false);
    const { setFiles, files, setSelectedFile } = useStore();

    const handleAddToWorkbench = () => {
        if (file.content) {
            setFiles({ ...files, [file.name]: { file: { contents: file.content } } });
            setSelectedFile(file.name);
            setShowMenu(false);
        }
    };

    return (
        <div className="relative">
            <button
                onClick={() => setShowMenu(!showMenu)}
                className={`flex items-center gap-2.5 px-3 py-2 rounded-lg transition-colors ${isDark ? 'bg-[#1a1a1a] hover:bg-[#1f1f1f]' : 'bg-gray-100 hover:bg-gray-200'}`}
            >
                <FileCode className={`w-4 h-4 ${isDark ? 'text-[#666]' : 'text-gray-400'}`} />
                <span className={`text-sm ${isDark ? 'text-[#ccc]' : 'text-gray-700'}`}>{file.name}</span>
            </button>

            {showMenu && (
                <>
                    <div className="fixed inset-0 z-10" onClick={() => setShowMenu(false)} />
                    <div className={`absolute top-full left-0 mt-1 rounded-lg overflow-hidden z-20 min-w-[160px] ${isDark ? 'bg-[#1a1a1a] border border-[#2a2a2a]' : 'bg-white border border-gray-200 shadow-lg'}`}>
                        <button
                            onClick={handleAddToWorkbench}
                            disabled={!file.content}
                            className={`w-full text-left px-3 py-2 text-sm flex items-center gap-2 ${isDark ? 'hover:bg-[#1f1f1f] text-[#ccc]' : 'hover:bg-gray-50 text-gray-700'} disabled:opacity-50`}
                        >
                            <FileCode className="w-4 h-4" />
                            Add to Workbench
                        </button>
                    </div>
                </>
            )}
        </div>
    );
}
